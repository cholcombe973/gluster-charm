options:
  volume_name:
    type: string
    default: test
    description: |
      The name of the Gluster volume to create.  This will also serve as the name
      of the mount point.  Example: mount -t glusterfs server1:/test
  brick_devices:
    type: string
    default:
    description: |
      Space separated device list to format and set up as brick volumes.

      These devices are the range of devices that will be checked for and
      used across all service units, in addition to any volumes attached
      via the --storage flag during deployment.
  ephemeral_unmount:
    type: string
    default:
    description: |
      Cloud instances provide ephermeral storage which is normally mounted
      on /mnt.

      Setting this option to the path of the ephemeral mountpoint will force
      an unmount of the corresponding device so that it can be used as a brick
      storage device.  This is useful for testing purposes (cloud deployment
      is not a typical use case).
  cluster_type:
    type: string
    default: DistributedAndReplicate
    description: |
      The type of volume to setup.  DistributedAndReplicate is sufficient
      for most use cases.
      Other options include: Distribute,
        Stripe,
        StripedAndReplicate,
        Disperse,
        DistributedAndStripe,
        DistributedAndReplicate,
        DistributedAndStripedAndReplicate,
        DistributedAndDisperse.
      For more information about these cluster types please see here:
      https://gluster.readthedocs.io/en/latest/Quick-Start-Guide/Architecture/#types-of-volumes
  replication_level:
    type: int
    default: 3
    description: |
      This sets how many replicas of the data should be stored in the cluster.
      Generally 2 or 3 will be fine for almost all use cases.  Greater than 3
      could be useful for read heavy uses cases.
  filesystem_type:
    type: string
    default: xfs
    description: |
      The filesystem type to use for each one of the bricks.  Can be either
      zfs, xfs, btrfs, or ext4. Note that zfs only works with ubuntu 16.04 or
      newer. General testing has shown that xfs is the most performant
      filesystem.
  splitbrain_policy:
    type: string
    default: size
    description: |
      Split brain means that the cluster can not come to consensus on which
      version of a file to serve to a client.
      This option set automatic resolution to split-brains in replica volumes
      Options include: ctime|mtime|size|majority. Set this to none to disable.
      Example: Setting this to "size" will pick the largest size automatically
      and delete the smaller size file. "majority" picks a file with identical
      mtime and size in more than half the number of bricks in the replica.
  source:
    type: string
    default: ppa:gluster/glusterfs-3.10
    description: |
      Optional configuration to support use of additional sources such as:

        - ppa:myteam/ppa
        - cloud:trusty-proposed/kilo
        - http://my.archive.com/ubuntu main

      The last option should be used in conjunction with the key configuration
      option. NOTE: Changing this configuration value after your cluster is
      deployed will initiate a rolling upgrade of the servers one by one.
  key:
    type: string
    default:
    description: |
      Key ID to import to the apt keyring to support use with arbitary source
      configuration from outside of Launchpad archives or PPA's.
  virtual_ip_addresses:
    type: string
    description: |
      By default NFSv3 is installed and started on all servers.  If the server
      the client is connected to dies NFSv3 doesn't have a failover mechanism.
      Setting this option to a space separated list of ip addresses cidr's to be
      used as virtual ip addresses on the cluster such as:
        - 10.0.0.6/24 10.0.0.7/24 10.0.0.8/24 10.0.0.9/24
          With a cluster of 2 machines would assign 2 virutal addresses
          to each host.
        - 2001:0db8:85a3:0000:0000:8a2e:0370:7334/24 2001:cdba:0000:0000:0000:0000:3257:9652/24
          With a cluster of 2 machines would assign 1 virtual address to each
          host.
      Each server will be assigned (# of ip addresses) / ( # of servers) ip
      addresses to use for quick failover.  The administrator is expected
      to create a DNS A record with the virtual ip addresses before setting
      this.  When clients connect to this charm it will attempt to resolve
      its own virtual ip and hand out the DNS address instead of the ip
      address if possible.  Upon failure of a server ctdb will issue a
      gratitous arp requests and migrate the virtual ip address over to a
      machine that is still up.  Note however that there are implications here
      for load balancing and moving an additional ip address to a server
      could increase load on it.
  cifs:
    type: boolean
    description: |
      Enable CIFS exporting of the volume. This option will enable windows
      clients to access the volume.
  sysctl:
    type: string
    default: '{ vm.vfs_cache_pressure: 100, vm.swappiness: 1 }'
    description: |
      YAML-formatted associative array of sysctl key/value pairs to be set
      persistently. By default we set pid_max, max_map_count and
      threads-max to a high value to avoid problems with large numbers (>20)
      of OSDs recovering. very large clusters should set those values even
      higher (e.g. max for kernel.pid_max is 4194303). Example settings for
      random and small file workloads:
        '{ vm.dirty_ratio: 5, vm.dirty_background_ratio: 2 }'
